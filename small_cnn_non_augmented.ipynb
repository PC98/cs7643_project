{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q2iufCeK7UAe",
        "outputId": "c2ab83ed-c4dd-403e-9382-ccaf426aba96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# If not running on Google Colab/Drive, skip this\n",
        "# Run this block first and follow the instructions to authorize mounting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0pwgKcby_Nu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "57595137-4c32-4c44-c3ff-41547886b8a1"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.math import confusion_matrix\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rh6F4tqGB2on",
        "colab": {}
      },
      "source": [
        "# If not running on Google Colab/Drive, modify this to root, \".\"\n",
        "GDRIVE = os.path.join('/', 'content', 'gdrive', 'My Drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXh7p2pzzMaX",
        "colab": {}
      },
      "source": [
        "RANDOM_SEED = 0\n",
        "\n",
        "OUTPUT_DATA_DIR = os.path.join(GDRIVE, 'data') # we will store train/ valid/ test/ directories here\n",
        "TRAIN_DATA_DIR = os.path.join(OUTPUT_DATA_DIR, 'train')\n",
        "VAL_DATA_DIR = os.path.join(OUTPUT_DATA_DIR, 'valid')\n",
        "TEST_DATA_DIR = os.path.join(OUTPUT_DATA_DIR, 'test')\n",
        "\n",
        "WASTE_TYPES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "IMG_HEIGHT = IMG_WIDTH = 256\n",
        "EPOCHS = 80\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "random.seed(RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VoE4uJGm0GRq",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'small_cnn_non_augmented'\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH , 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.2),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Dropout(0.2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(len(WASTE_TYPES), activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e0UyIMIxBJaM",
        "outputId": "77b86e02-1b74-4864-c679-bb21962ca7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                3686464   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 3,715,494\n",
            "Trainable params: 3,715,494\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4kX8BX2BU3O",
        "outputId": "8cbd7a71-6d1a-4f75-9aa6-b9af3d01a06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# using default params: target_size=(256, 256)\n",
        "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR, batch_size=BATCH_SIZE)\n",
        "val_generator = val_datagen.flow_from_directory(VAL_DATA_DIR, batch_size=BATCH_SIZE)\n",
        "# don't shuffle test set, it will be easier to predict then\n",
        "test_generator = test_datagen.flow_from_directory(TEST_DATA_DIR, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#sample_training_images, _ = next(train_generator)\n",
        "#plotImages(sample_training_images[:5])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1514 images belonging to 6 classes.\n",
            "Found 505 images belonging to 6 classes.\n",
            "Found 508 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-5pITiASxw8",
        "outputId": "bac64f43-c763-49f4-9640-ab38d0417f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get these values from the above cell, or from prepare_train_test_data.ipynb\n",
        "total_train = 1514\n",
        "total_val = 505\n",
        "total_test = 508\n",
        "print(total_train, total_val, total_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1514 505 508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsBz8oMEBXPv",
        "outputId": "51063e56-54be-4489-b62b-115da845279b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=ceil(total_train / BATCH_SIZE),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=ceil(total_val / BATCH_SIZE),\n",
        "    callbacks=[ModelCheckpoint(os.path.join(GDRIVE, f'{MODEL_NAME}.h5'), save_best_only=True, save_weights_only=True, verbose=1)])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "48/48 [==============================] - ETA: 0s - loss: 1.5886 - accuracy: 0.3217 \n",
            "Epoch 00001: val_loss improved from inf to 1.56703, saving model to /content/gdrive/My Drive/small_cnn_non_augmented.h5\n",
            "48/48 [==============================] - 1018s 21s/step - loss: 1.5886 - accuracy: 0.3217 - val_loss: 1.5670 - val_accuracy: 0.3842\n",
            "Epoch 2/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 1.4633 - accuracy: 0.3870\n",
            "Epoch 00002: val_loss improved from 1.56703 to 1.34096, saving model to /content/gdrive/My Drive/small_cnn_non_augmented.h5\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 1.4630 - accuracy: 0.3864 - val_loss: 1.3410 - val_accuracy: 0.4277\n",
            "Epoch 3/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 1.3560 - accuracy: 0.4568\n",
            "Epoch 00003: val_loss improved from 1.34096 to 1.32827, saving model to /content/gdrive/My Drive/small_cnn_non_augmented.h5\n",
            "48/48 [==============================] - 11s 220ms/step - loss: 1.3532 - accuracy: 0.4571 - val_loss: 1.3283 - val_accuracy: 0.4851\n",
            "Epoch 4/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 1.3172 - accuracy: 0.4621\n",
            "Epoch 00004: val_loss improved from 1.32827 to 1.28661, saving model to /content/gdrive/My Drive/small_cnn_non_augmented.h5\n",
            "48/48 [==============================] - 10s 215ms/step - loss: 1.3136 - accuracy: 0.4637 - val_loss: 1.2866 - val_accuracy: 0.5030\n",
            "Epoch 5/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 1.2019 - accuracy: 0.5339\n",
            "Epoch 00005: val_loss improved from 1.28661 to 1.17184, saving model to /content/gdrive/My Drive/small_cnn_non_augmented.h5\n",
            "48/48 [==============================] - 12s 241ms/step - loss: 1.2037 - accuracy: 0.5337 - val_loss: 1.1718 - val_accuracy: 0.5743\n",
            "Epoch 6/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 1.1427 - accuracy: 0.5539\n",
            "Epoch 00006: val_loss did not improve from 1.17184\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 1.1401 - accuracy: 0.5542 - val_loss: 1.1893 - val_accuracy: 0.5604\n",
            "Epoch 7/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 1.0119 - accuracy: 0.6084\n",
            "Epoch 00007: val_loss improved from 1.17184 to 1.10347, saving model to /content/gdrive/My Drive/small_cnn_non_augmented.h5\n",
            "48/48 [==============================] - 10s 212ms/step - loss: 1.0135 - accuracy: 0.6083 - val_loss: 1.1035 - val_accuracy: 0.5980\n",
            "Epoch 8/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.9333 - accuracy: 0.6376\n",
            "Epoch 00008: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.9250 - accuracy: 0.6380 - val_loss: 1.1619 - val_accuracy: 0.5564\n",
            "Epoch 9/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.8269 - accuracy: 0.6848\n",
            "Epoch 00009: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.8420 - accuracy: 0.6836 - val_loss: 1.1650 - val_accuracy: 0.5604\n",
            "Epoch 10/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.7456 - accuracy: 0.7214\n",
            "Epoch 00010: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 207ms/step - loss: 0.7402 - accuracy: 0.7226 - val_loss: 1.3303 - val_accuracy: 0.5010\n",
            "Epoch 11/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.7473\n",
            "Epoch 00011: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 204ms/step - loss: 0.6841 - accuracy: 0.7470 - val_loss: 1.4900 - val_accuracy: 0.5347\n",
            "Epoch 12/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.6176 - accuracy: 0.7739\n",
            "Epoch 00012: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 203ms/step - loss: 0.6216 - accuracy: 0.7741 - val_loss: 1.4019 - val_accuracy: 0.5446\n",
            "Epoch 13/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.5708 - accuracy: 0.7819\n",
            "Epoch 00013: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.5664 - accuracy: 0.7820 - val_loss: 1.2643 - val_accuracy: 0.5663\n",
            "Epoch 14/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.8178\n",
            "Epoch 00014: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.4732 - accuracy: 0.8184 - val_loss: 1.3270 - val_accuracy: 0.6059\n",
            "Epoch 15/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.4239 - accuracy: 0.8491\n",
            "Epoch 00015: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.4251 - accuracy: 0.8494 - val_loss: 1.5280 - val_accuracy: 0.5921\n",
            "Epoch 16/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.8378\n",
            "Epoch 00016: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 196ms/step - loss: 0.4663 - accuracy: 0.8388 - val_loss: 1.3961 - val_accuracy: 0.5921\n",
            "Epoch 17/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.8830\n",
            "Epoch 00017: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.3452 - accuracy: 0.8824 - val_loss: 1.4592 - val_accuracy: 0.6178\n",
            "Epoch 18/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8870\n",
            "Epoch 00018: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.2828 - accuracy: 0.8864 - val_loss: 1.8052 - val_accuracy: 0.5921\n",
            "Epoch 19/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2738 - accuracy: 0.8969\n",
            "Epoch 00019: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.2756 - accuracy: 0.8963 - val_loss: 1.7958 - val_accuracy: 0.5861\n",
            "Epoch 20/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9082\n",
            "Epoch 00020: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.2589 - accuracy: 0.9082 - val_loss: 1.5346 - val_accuracy: 0.6337\n",
            "Epoch 21/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2707 - accuracy: 0.8969\n",
            "Epoch 00021: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.2705 - accuracy: 0.8970 - val_loss: 1.9082 - val_accuracy: 0.5921\n",
            "Epoch 22/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8830\n",
            "Epoch 00022: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 195ms/step - loss: 0.2927 - accuracy: 0.8824 - val_loss: 1.7736 - val_accuracy: 0.6059\n",
            "Epoch 23/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2493 - accuracy: 0.9129\n",
            "Epoch 00023: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.2513 - accuracy: 0.9128 - val_loss: 2.3164 - val_accuracy: 0.5505\n",
            "Epoch 24/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9182\n",
            "Epoch 00024: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.2194 - accuracy: 0.9181 - val_loss: 2.1803 - val_accuracy: 0.5960\n",
            "Epoch 25/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2083 - accuracy: 0.9282\n",
            "Epoch 00025: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.2135 - accuracy: 0.9273 - val_loss: 2.0892 - val_accuracy: 0.5881\n",
            "Epoch 26/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2195 - accuracy: 0.9182\n",
            "Epoch 00026: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.2174 - accuracy: 0.9188 - val_loss: 2.0541 - val_accuracy: 0.5861\n",
            "Epoch 27/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9169\n",
            "Epoch 00027: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.2158 - accuracy: 0.9174 - val_loss: 2.2329 - val_accuracy: 0.5426\n",
            "Epoch 28/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.2006 - accuracy: 0.9176\n",
            "Epoch 00028: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.2009 - accuracy: 0.9181 - val_loss: 1.8516 - val_accuracy: 0.5881\n",
            "Epoch 29/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.9328\n",
            "Epoch 00029: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1900 - accuracy: 0.9326 - val_loss: 2.1709 - val_accuracy: 0.6000\n",
            "Epoch 30/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9481\n",
            "Epoch 00030: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1471 - accuracy: 0.9485 - val_loss: 2.4521 - val_accuracy: 0.5762\n",
            "Epoch 31/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9269\n",
            "Epoch 00031: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1860 - accuracy: 0.9273 - val_loss: 2.0009 - val_accuracy: 0.6099\n",
            "Epoch 32/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9415\n",
            "Epoch 00032: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.1659 - accuracy: 0.9419 - val_loss: 2.1855 - val_accuracy: 0.5842\n",
            "Epoch 33/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9315\n",
            "Epoch 00033: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1690 - accuracy: 0.9306 - val_loss: 1.9879 - val_accuracy: 0.6277\n",
            "Epoch 34/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9402\n",
            "Epoch 00034: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.1424 - accuracy: 0.9406 - val_loss: 2.3510 - val_accuracy: 0.5842\n",
            "Epoch 35/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9461\n",
            "Epoch 00035: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1417 - accuracy: 0.9465 - val_loss: 2.3897 - val_accuracy: 0.5703\n",
            "Epoch 36/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9362\n",
            "Epoch 00036: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1652 - accuracy: 0.9366 - val_loss: 2.7874 - val_accuracy: 0.5723\n",
            "Epoch 37/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9295\n",
            "Epoch 00037: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1680 - accuracy: 0.9300 - val_loss: 2.3118 - val_accuracy: 0.5525\n",
            "Epoch 38/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1421 - accuracy: 0.9461\n",
            "Epoch 00038: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1392 - accuracy: 0.9465 - val_loss: 3.0740 - val_accuracy: 0.5644\n",
            "Epoch 39/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9588\n",
            "Epoch 00039: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.1171 - accuracy: 0.9584 - val_loss: 2.3588 - val_accuracy: 0.5822\n",
            "Epoch 40/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1262 - accuracy: 0.9475\n",
            "Epoch 00040: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1264 - accuracy: 0.9472 - val_loss: 2.6744 - val_accuracy: 0.5980\n",
            "Epoch 41/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9435\n",
            "Epoch 00041: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1457 - accuracy: 0.9439 - val_loss: 2.6846 - val_accuracy: 0.5604\n",
            "Epoch 42/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 0.9468\n",
            "Epoch 00042: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 202ms/step - loss: 0.1286 - accuracy: 0.9465 - val_loss: 3.1100 - val_accuracy: 0.5960\n",
            "Epoch 43/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9375\n",
            "Epoch 00043: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 205ms/step - loss: 0.1486 - accuracy: 0.9373 - val_loss: 2.8198 - val_accuracy: 0.6099\n",
            "Epoch 44/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9461\n",
            "Epoch 00044: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 206ms/step - loss: 0.1499 - accuracy: 0.9465 - val_loss: 3.0731 - val_accuracy: 0.5505\n",
            "Epoch 45/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 0.9441\n",
            "Epoch 00045: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1501 - accuracy: 0.9445 - val_loss: 2.9113 - val_accuracy: 0.5723\n",
            "Epoch 46/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9441\n",
            "Epoch 00046: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1679 - accuracy: 0.9439 - val_loss: 2.2448 - val_accuracy: 0.5980\n",
            "Epoch 47/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.9535\n",
            "Epoch 00047: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1239 - accuracy: 0.9531 - val_loss: 2.5264 - val_accuracy: 0.6079\n",
            "Epoch 48/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9495\n",
            "Epoch 00048: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1225 - accuracy: 0.9498 - val_loss: 2.6094 - val_accuracy: 0.5743\n",
            "Epoch 49/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9548\n",
            "Epoch 00049: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1195 - accuracy: 0.9531 - val_loss: 2.5129 - val_accuracy: 0.5861\n",
            "Epoch 50/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9428\n",
            "Epoch 00050: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.1447 - accuracy: 0.9432 - val_loss: 2.7051 - val_accuracy: 0.5861\n",
            "Epoch 51/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9594\n",
            "Epoch 00051: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1068 - accuracy: 0.9597 - val_loss: 2.3269 - val_accuracy: 0.6099\n",
            "Epoch 52/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9568\n",
            "Epoch 00052: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 200ms/step - loss: 0.1068 - accuracy: 0.9571 - val_loss: 2.5629 - val_accuracy: 0.6139\n",
            "Epoch 53/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9588\n",
            "Epoch 00053: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 200ms/step - loss: 0.1112 - accuracy: 0.9584 - val_loss: 2.6065 - val_accuracy: 0.5782\n",
            "Epoch 54/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9588\n",
            "Epoch 00054: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1141 - accuracy: 0.9584 - val_loss: 2.8637 - val_accuracy: 0.6040\n",
            "Epoch 55/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9495\n",
            "Epoch 00055: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1056 - accuracy: 0.9498 - val_loss: 2.6960 - val_accuracy: 0.5802\n",
            "Epoch 56/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9548\n",
            "Epoch 00056: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1156 - accuracy: 0.9551 - val_loss: 3.2552 - val_accuracy: 0.5465\n",
            "Epoch 57/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9588\n",
            "Epoch 00057: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1111 - accuracy: 0.9584 - val_loss: 3.0951 - val_accuracy: 0.5861\n",
            "Epoch 58/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9628\n",
            "Epoch 00058: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.0807 - accuracy: 0.9630 - val_loss: 3.8257 - val_accuracy: 0.5723\n",
            "Epoch 59/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9521\n",
            "Epoch 00059: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1261 - accuracy: 0.9524 - val_loss: 2.4878 - val_accuracy: 0.5861\n",
            "Epoch 60/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9707\n",
            "Epoch 00060: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 200ms/step - loss: 0.0701 - accuracy: 0.9709 - val_loss: 3.4770 - val_accuracy: 0.5861\n",
            "Epoch 61/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9621\n",
            "Epoch 00061: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.0955 - accuracy: 0.9624 - val_loss: 3.4654 - val_accuracy: 0.5861\n",
            "Epoch 62/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 0.9561\n",
            "Epoch 00062: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1328 - accuracy: 0.9564 - val_loss: 2.2808 - val_accuracy: 0.5941\n",
            "Epoch 63/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.9581\n",
            "Epoch 00063: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1019 - accuracy: 0.9584 - val_loss: 2.8775 - val_accuracy: 0.6218\n",
            "Epoch 64/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9541\n",
            "Epoch 00064: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 197ms/step - loss: 0.1178 - accuracy: 0.9544 - val_loss: 2.9016 - val_accuracy: 0.5762\n",
            "Epoch 65/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0953 - accuracy: 0.9621\n",
            "Epoch 00065: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.0938 - accuracy: 0.9624 - val_loss: 3.0481 - val_accuracy: 0.5842\n",
            "Epoch 66/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1249 - accuracy: 0.9508\n",
            "Epoch 00066: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 9s 198ms/step - loss: 0.1236 - accuracy: 0.9511 - val_loss: 3.0503 - val_accuracy: 0.6059\n",
            "Epoch 67/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9548\n",
            "Epoch 00067: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.1135 - accuracy: 0.9544 - val_loss: 3.2093 - val_accuracy: 0.5644\n",
            "Epoch 68/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.9548\n",
            "Epoch 00068: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1292 - accuracy: 0.9544 - val_loss: 2.6391 - val_accuracy: 0.5782\n",
            "Epoch 69/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 0.9395\n",
            "Epoch 00069: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.1723 - accuracy: 0.9392 - val_loss: 2.5267 - val_accuracy: 0.5624\n",
            "Epoch 70/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9561\n",
            "Epoch 00070: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1009 - accuracy: 0.9564 - val_loss: 2.8872 - val_accuracy: 0.5782\n",
            "Epoch 71/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0991 - accuracy: 0.9581\n",
            "Epoch 00071: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.0971 - accuracy: 0.9584 - val_loss: 2.7850 - val_accuracy: 0.5941\n",
            "Epoch 72/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9694\n",
            "Epoch 00072: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.0825 - accuracy: 0.9696 - val_loss: 3.3905 - val_accuracy: 0.5842\n",
            "Epoch 73/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9634\n",
            "Epoch 00073: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.0915 - accuracy: 0.9637 - val_loss: 2.9041 - val_accuracy: 0.5762\n",
            "Epoch 74/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9707\n",
            "Epoch 00074: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.0734 - accuracy: 0.9709 - val_loss: 3.1185 - val_accuracy: 0.5941\n",
            "Epoch 75/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9714\n",
            "Epoch 00075: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 210ms/step - loss: 0.0818 - accuracy: 0.9709 - val_loss: 3.1002 - val_accuracy: 0.5921\n",
            "Epoch 76/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9521\n",
            "Epoch 00076: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 201ms/step - loss: 0.1296 - accuracy: 0.9518 - val_loss: 2.7679 - val_accuracy: 0.6020\n",
            "Epoch 77/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 0.9701\n",
            "Epoch 00077: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 200ms/step - loss: 0.0778 - accuracy: 0.9696 - val_loss: 3.1720 - val_accuracy: 0.5861\n",
            "Epoch 78/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1002 - accuracy: 0.9641\n",
            "Epoch 00078: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1078 - accuracy: 0.9630 - val_loss: 3.7734 - val_accuracy: 0.5327\n",
            "Epoch 79/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1202 - accuracy: 0.9588\n",
            "Epoch 00079: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 199ms/step - loss: 0.1187 - accuracy: 0.9590 - val_loss: 3.0247 - val_accuracy: 0.5584\n",
            "Epoch 80/80\n",
            "47/48 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9634\n",
            "Epoch 00080: val_loss did not improve from 1.10347\n",
            "48/48 [==============================] - 10s 198ms/step - loss: 0.0983 - accuracy: 0.9637 - val_loss: 3.2532 - val_accuracy: 0.5802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5wIy8JZDUIHU",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Learning Curve, small CNN with non-augmented data')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.show()\n",
        "plt.savefig(os.path.join(GDRIVE, f'{MODEL_NAME}_learning_curve.png'))\n",
        "plt.close()\n",
        "\n",
        "with open(os.path.join(GDRIVE, f'{MODEL_NAME}_history.pickle'), 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7Jocz11MAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model() # create a new instance\n",
        "model.load_weights(os.path.join(GDRIVE, f'{MODEL_NAME}.h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l40umB-6ABNq",
        "colab": {}
      },
      "source": [
        "test_predictions = np.argmax(model.predict(test_generator, batch_size=BATCH_SIZE, steps=ceil(total_test / BATCH_SIZE)), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y5gGHpPv51Fa",
        "colab": {}
      },
      "source": [
        "test_cm = np.array(confusion_matrix(test_generator.labels, test_predictions))\n",
        "df_cm = pd.DataFrame(test_cm, WASTE_TYPES, WASTE_TYPES)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.savefig(os.path.join(GDRIVE, f'{MODEL_NAME}_confusion_matrix.png'))\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jvm5KNd-6J8A",
        "outputId": "8ad93982-5837-497d-90e1-e27333d56b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = np.trace(test_cm) / np.sum(test_cm)\n",
        "print(f'Test accruracy: {accuracy * 100:.2f}%')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accruracy: 61.22%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}